<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Software Carpentry: Parallel Computing</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://software-carpentry.org" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/software-carpentry-banner.png" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <a href="index.html"><h1 class="title">Parallel Computing</h1></a>
          <h2 class="subtitle">Parallelizing the Mandelbrot Program</h2>
          <section class="objectives panel panel-warning">
<div class="panel-heading">
<h2 id="learning-objectives"><span class="glyphicon glyphicon-certificate"></span>Learning Objectives</h2>
</div>
<div class="panel-body">
<ul>
<li>Using a serial program as a template for a parallel one.</li>
<li>Stepwise introduction of parallel framework.</li>
<li>Parallelizing Loops.</li>
</ul>
</div>
</section>
<p>OK, now we made multiple processes, made them talk to each other through point-to-point communication, so we’re ready to try to exploit this to speed up our Mandelbrot program. At this point, that should look something like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co">#! /usr/bin/env python3</span>

<span class="im">import</span> cmath
<span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> sys

nr<span class="op">=</span>   <span class="bu">int</span>(sys.argv[<span class="dv">1</span>])
ni<span class="op">=</span>   <span class="bu">int</span>(sys.argv[<span class="dv">2</span>])
rei<span class="op">=</span><span class="bu">float</span>(sys.argv[<span class="dv">3</span>])
ref<span class="op">=</span><span class="bu">float</span>(sys.argv[<span class="dv">4</span>])
imi<span class="op">=</span><span class="bu">float</span>(sys.argv[<span class="dv">5</span>])
imf<span class="op">=</span><span class="bu">float</span>(sys.argv[<span class="dv">6</span>])
imax<span class="op">=</span> <span class="bu">int</span>(sys.argv[<span class="dv">7</span>])
dr<span class="op">=</span>(ref<span class="op">-</span>rei)<span class="op">/</span>nr
di<span class="op">=</span>(imf<span class="op">-</span>imi)<span class="op">/</span>ni

<span class="kw">def</span> point (ir,ii):
    rl<span class="op">=</span>ir<span class="op">*</span>dr<span class="op">+</span>rei
    im<span class="op">=</span>ii<span class="op">*</span>di<span class="op">+</span>imi
    <span class="cf">return</span> rl<span class="op">+</span>im<span class="op">*</span>1j

<span class="kw">def</span> mandit (b):
    z<span class="op">=</span><span class="fl">0.0</span>
    <span class="cf">for</span> it <span class="op">in</span> <span class="bu">range</span>(<span class="dv">1</span>,imax<span class="dv">+1</span>):
        z<span class="op">=</span>z<span class="op">*</span>z<span class="op">+</span>b
        <span class="cf">if</span> (<span class="bu">abs</span>(z)<span class="op">&gt;</span><span class="fl">2.0</span>):
            <span class="cf">break</span>
    <span class="cf">return</span> it

manrow<span class="op">=</span>np.zeros(nr)
mandel<span class="op">=</span>np.zeros((nr,ni))
<span class="cf">for</span> iindex <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>,ni):
    <span class="cf">for</span> rindex <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>,nr):
        b<span class="op">=</span>point(rindex,iindex)
        manrow[rindex]<span class="op">=</span>mandit(b)
    mandel[iindex][:]<span class="op">=</span>manrow[:]

image<span class="op">=</span>plt.imshow(mandel)
plt.show(image)</code></pre></div>
<p>If it doesn’t, no worries. There is a hidden version of the program that looks exactly like this in your “mandel” directory and you can copy it to your current mandel program like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">cp .mandel_serial MPImandel.py</code></pre></div>
<p>Then edit MPImandel.py. We have various segments in the code:</p>
<ul>
<li>Hash-bang header to tell the system we’re using Python3</li>
<li>Importing various packages</li>
<li>Taking dimensions etc from the input line</li>
<li>Little routine “point” to convert index numbers into real and imaginary part</li>
<li>Other routine “mandel” to performm and count iterations</li>
<li>Main loops going through every pixel row-wise</li>
<li>Calls to plt package to make and display image</li>
</ul>
<p>To turn this parallel, we need to:</p>
<ul>
<li>Import the MPI package</li>
<li>Set a communicator</li>
<li>Determine rank and size</li>
<li>Insert if/else statements to separate what needs to be done by only one process (rank 0 prints and plots stuff and handles the total of the results) from what needs to be done by all of them (computing the proper share of actual iterations).</li>
<li>Insert MPI function calls to send results from rank&gt;0 processes to rank 0 process</li>
<li>Throw in timing routine so we can check if this scales.</li>
</ul>
<p>OK, let’s get to it. First the simple stuff. To the import list on the top of the program we add:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> mpi4py <span class="im">import</span> MPI
comm<span class="op">=</span>MPI.COMM_WORLD
rank<span class="op">=</span>comm.Get_rank()
size<span class="op">=</span>comm.Get_size()</code></pre></div>
<p>That are the first two bullet points above. This needs to be done anyway, irrespective of the content of the program. As usual we can safe here and test if we broke anything by doing this. We should test with mpirun but use only one process, since we haven’t really made any accomodation for multiple processes yet.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">mpirun <span class="op">-</span>np <span class="dv">1</span> .<span class="op">/</span>MPImandel.py <span class="dv">200</span> <span class="dv">200</span> <span class="op">-</span><span class="fl">1.5</span> <span class="fl">0.5</span> <span class="op">-</span><span class="dv">1</span>. <span class="dv">1</span>. <span class="dv">1000</span></code></pre></div>
<p>We’ve chosen some reasonable arguments that display most of the Mandelbrot set with a medium resolution. If this works out alright we know that the MPI package works and we can do basic MPI calls. Next step is to add the stuff that needs to be done by only one process (let’s say rank 0 because that s always available). We can take this opportunity to do the timing as well. So let’s put an “if” statement in front of the line where we make our “mandel” data structure by filling it with zeroes. And add a start marker for timing:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">manrow<span class="op">=</span>np.zeros(nr)
<span class="cf">if</span> (rank<span class="op">==</span><span class="dv">0</span>):
    mandel<span class="op">=</span>np.zeros((nr,ni))
    start<span class="op">=</span>tm.time()</code></pre></div>
<p>Don’t forget the finishing blank line or else we end up having everything in our if statement. Note that the “manrow” structure (which contains a line of values) is needed by all processes, so it has to be outside the if statement. The “start” line is calling a timing routine first. Let’s leave the main loops in peace for now because we’re not quite ready yet for actual work distribution. But we can put another “if” in front of the stuff at the bottom, because printing/plotting results is going to be done only by rank 0:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">if</span>(rank<span class="op">==</span><span class="dv">0</span>):
    end<span class="op">=</span>tm.time()
    <span class="bu">print</span> (<span class="st">&quot;Done in &quot;</span>,end<span class="op">-</span>start,<span class="st">&quot;seconds.&quot;</span>)
    image<span class="op">=</span>plt.imshow(mandel)
    plt.show(image)</code></pre></div>
<p>We also call the timing again and print out the difference as the time it took. Again, don’t forget the blank line. Now let’s test one more time with only one process to make sure.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">$ mpirun <span class="op">-</span>np <span class="dv">1</span> .<span class="op">/</span>MPImandel.py <span class="dv">200</span> <span class="dv">200</span> <span class="op">-</span><span class="fl">1.5</span> <span class="fl">0.5</span> <span class="op">-</span><span class="dv">1</span>. <span class="dv">1</span>. <span class="dv">1000</span>
Done <span class="op">in</span>  <span class="fl">3.833190441131592</span> seconds.
(...plot display...)</code></pre></div>
<p>Now we have pretty much put up the framework and we need to tackle the loops. The outermost of them (the one over iindex, which corresponds to rows of pixels that correspond to a fixed imaginary part) is the one we want to “parallelize”. An easy way to do this is to compute a bunch of them on one process and another on another.</p>
<p>But there is a problem: It turns out that the stuff inside of the Mandelbrot set takes longer to compute than the areas outside it. Which means if we are grouping the rows together like that we end up having one process (the one that works near an imaginary part of zero) do a lot more work than the others, and that isn’t good. Remember the “workload balance” principle mentioned earlier.</p>
<p>So it’s much better to go like this: instead of going through the loop one-by-one we “skip” values of iindex. Exactly as many as there are processes. And each of the processes computes one of the rows in between. So rank 0 get row 0, 4, 8, etc… and rank 1 gets 1,5,9, etc… if there are 4 processes in total. This means that the new loops looks like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">for</span> iindex <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>,ni,size):
    <span class="cf">for</span> rindex <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>,nr):
        b<span class="op">=</span>point(rindex,iindex<span class="op">+</span>rank)
        manrow[rindex]<span class="op">=</span>mandit(b)</code></pre></div>
<p>Note that all we did was add “size” as a stride in the range call,, and added “rank” in the point() computation so that each of the processes (ranks) compute a different set of points. Now we need to modify the core of the loops. Rank 0 will first use its own version of “manrow” which contains one row of points to fill the proper part of the total data structure “mandel”</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    <span class="cf">if</span> (rank<span class="op">==</span><span class="dv">0</span>):
        mandel[iindex][:]<span class="op">=</span>manrow[:]</code></pre></div>
<p>Then it gets the versions on the other processes one-by-one through a “MPI.Recv” call and slots them into the proper spot in “mandel”:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">        <span class="cf">for</span> irank <span class="op">in</span> <span class="bu">range</span>(<span class="dv">1</span>,size):
            comm.Recv(manrow, source<span class="op">=</span>irank, tag<span class="op">=</span><span class="dv">11</span>)
            mandel[iindex<span class="op">+</span>irank][:]<span class="op">=</span>manrow[:]</code></pre></div>
<p>Note that the loop index irank is “the other process’ rank”. The last thing that remains to do is to have the individual ranks call the MPI.Send function to send their “pixel rows” to rank 0.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    <span class="cf">else</span>:
        comm.Send(manrow, dest<span class="op">=</span><span class="dv">0</span>, tag<span class="op">=</span><span class="dv">11</span>)
    comm.Barrier()</code></pre></div>
<p>For good measure, we have called an MPI.Barrier so that all processes are done with everything before we move on to the next set of rows. We didn’t even have to specify the data types of manrow, or the size of the array we’re sending around. MPI (and Python) is smart enough to do this for us. We also don’t need a different tag for every communication, because between a given set of processes (i.e. 0 and another one) there’s at any given time only one around, and no extra labeling is required. This is one of the reasons for having that barrier, so that multiple communications can’t “run into each other”.</p>
<p>Let’s see if it works, first with one processor:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">mpirun</span> -np 1 ./MPImandel.py 200 200 -1.5 0.5 -1. 1. 1000
<span class="kw">Done</span> in  3.4627363681793213 seconds.</code></pre></div>
<p>Then with 2, 4, and 8:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">mpirun</span> -np 2 ./MPImandel.py 200 200 -1.5 0.5 -1. 1. 1000
<span class="kw">Done</span> in  1.801743745803833 seconds.
$ <span class="kw">mpirun</span> -np 4 ./MPImandel.py 200 200 -1.5 0.5 -1. 1. 1000
<span class="kw">Done</span> in  0.8913767337799072 seconds.
$ <span class="kw">mpirun</span> -np 8 ./MPImandel.py 200 200 -1.5 0.5 -1. 1. 1000
<span class="kw">Done</span> in  0.48674607276916504 seconds.</code></pre></div>
<p>That is pretty good scaling for a simple program like this. Welcome to the wild and wonderful world of high-performance computing.</p>
<section class="challenge panel panel-success">
<div class="panel-heading">
<h2 id="same-thing-different-way"><span class="glyphicon glyphicon-pencil"></span>Same thing different way</h2>
</div>
<div class="panel-body">
<p>This is probably going to be home work. Write a program that does the same thing as our MPImandel program, but uses a Bcast()/Reduce() approach to do it. Hints: You won’t need an “mrow” array that contains a specific pixel row. Instead you have a copy of “mandel” (i.e. all the pixels) on each process. First you fill it all with zeroes, then you ucompute only those rows in the total structure that the specific process needs. Finally you use Reduce() to send them to Rank 0. For each process there will be a lot of zeroes, but that won’t matter because zeroes will not contribute to the MPI_SUM.</p>
</div>
</section>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="http://software-carpentry.org">Software Carpentry</a>
        <a class="label swc-blue-bg" href="https://github.com/swcarpentry/python-novice-inflammation">Source</a>
        <a class="label swc-blue-bg" href="mailto:admin@software-carpentry.org">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="http://software-carpentry.org/v5/js/jquery-1.9.1.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
  </body>
</html>
